{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ae10cb1-6d19-47ef-98fd-0474841918ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "import cobra\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import GEMtoGRAPH as gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "181151a3-7cc4-4572-99ea-13b668dae70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 373)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cobra.io.load_json_model('redYeast_ST8943_fdp1.json')\n",
    "S = cobra.util.array.create_stoichiometric_matrix(model, array_type='DataFrame')\n",
    "S.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf38acb2-5ee5-4661-abb7-e60f124d4be5",
   "metadata": {},
   "source": [
    "# MFG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0887caf",
   "metadata": {},
   "source": [
    "#### Load TFA fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "54acba48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero flux reactions: 373\n",
      "TFA fluxes: 373\n"
     ]
    }
   ],
   "source": [
    "# load tfa fluxes and send them to graph construction functions\n",
    "tfa = pd.read_csv('fluxes_for_graph.csv', index_col=0)\n",
    "tfa = tfa.head(1)\n",
    "\n",
    "zero_flux = [col for col in tfa.columns if (tfa[col] == 0).all()]\n",
    "\n",
    "print('Zero flux reactions:',len(zero_flux))\n",
    "\n",
    "tfa.drop(columns=zero_flux, inplace=True)\n",
    "print(\"TFA fluxes:\", tfa.shape[1])\n",
    "\n",
    "# For _reverse reactions we should change the sign of the flux to negative\n",
    "for col in tfa.columns:\n",
    "    if '_reverse' in col: tfa[col] = -tfa[col]\n",
    "\n",
    "\n",
    "tfa.rename(columns={col: col.split(\"_reverse_\")[0] for col in tfa.columns}, inplace=True)\n",
    "\n",
    "tfa_flux = tfa.iloc[0].values\n",
    "tfa_flux = pd.DataFrame(columns=['fluxes'], data=tfa_flux)\n",
    "tfa_flux.index = S.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61920d61",
   "metadata": {},
   "source": [
    "### Create MFG Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd8996a0-d873-404b-aa6a-112d49eb93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 746 \n",
      "# edges: 6157\n"
     ]
    }
   ],
   "source": [
    "M, S_2m, G = gg.MFG(S, model, tfa_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "489dec3c-6707-434c-a0e4-593f78a1dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nodes: 373 \n",
      "# edges: 6157\n"
     ]
    }
   ],
   "source": [
    "# Remove isolated nodes from G\n",
    "isolated_nodes = list(nx.isolates(G))\n",
    "G.remove_nodes_from(isolated_nodes)\n",
    "\n",
    "print(\"# nodes:\", G.number_of_nodes(), \"\\n# edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806c87c-843b-4eab-b8e1-ba546324007f",
   "metadata": {},
   "source": [
    "## Read ORACLE's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "44e52311-7ade-434c-bb56-66c04aa52019",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = pd.read_csv('saturations.csv', index_col=0)\n",
    "gamma = pd.read_csv('gamma.csv', index_col=0)\n",
    "vmax = pd.read_csv('Vmax_matrix.csv', index_col=0)\n",
    "\n",
    "gamma = gamma.head(1)\n",
    "sigma = sigma.head(1)\n",
    "vmax = vmax.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ffe4c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the reactions that are the reversible version\n",
    "rev_rxn = []\n",
    "for node in list(G.nodes()):\n",
    "    if node.split(\"?\")[0] == 'rev': rev_rxn.append(node.split(\"?\")[1])\n",
    "\n",
    "# rename the reactions of gamma; if it's the reversible one add rev? to the column name\n",
    "for col in gamma.columns:\n",
    "    if col in rev_rxn: gamma.rename(columns={col:'rev?'+col}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "42b19be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Graph but not in gamma: ['EX_lac__D_e', 'EX_mal__L_e', 'EX_akg_e', 'EX_2phetoh_e', 'EX_acald_e', 'EX_ac_e', 'EX_gam6p_e', 'EX_co2_e', 'EX_cit_e', 'EX_etoh_e', 'EX_fum_e', 'EX_gly_e', 'EX_gcald_e', 'EX_glx_e', 'EX_id3acald_e', 'EX_ala__L_e', 'EX_asn__L_e', 'EX_asp__L_e', 'EX_cys__L_e', 'EX_glu__L_e', 'EX_gln__L_e', 'EX_phe__L_e', 'EX_ser__L_e', 'EX_trp__L_e', 'EX_tyr__L_e', 'EX_oaa_e', 'EX_pacald_e', 'EX_pyr_e', 'EX_succ_e', 'EX_ind3eth_e', 'EX_h2o_e', 'EX_g6p_e', 'EX_g1p_e', 'EX_2pg_e', 'EX_pser__L_e', 'EX_ppi_e', 'EX_pep_e', 'EX_cbp_e', 'EX_6pgc_e', 'EX_3pg_e', 'EX_cmp_e', 'GROWTH', 'EX_ccm_e', 'EX_pca_e', 'rev?EX_nh4_e', 'rev?EX_glc__D_e', 'rev?EX_h_e', 'rev?EX_fe2_e', 'rev?EX_o2_e', 'rev?EX_pi_e', 'rev?EX_k_e', 'rev?EX_na1_e', 'rev?EX_so4_e', 'rev?EX_cl_e', 'rev?EX_cu2_e', 'rev?EX_mn2_e', 'rev?EX_zn2_e', 'rev?EX_mg2_e', 'rev?EX_ca2_e']\n",
      "\n",
      "In gamma but not in Graph: []\n"
     ]
    }
   ],
   "source": [
    "listA = list(G.nodes())\n",
    "listB = gamma.columns\n",
    "\n",
    "print('In Graph but not in gamma:', [item for item in listA if item not in listB])\n",
    "print()\n",
    "print('In gamma but not in Graph:', [item for item in listB if item not in listA])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4103336f",
   "metadata": {},
   "source": [
    "#### Add `gamma` values as Graph node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f5a3dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in gamma.columns:\n",
    "    try:\n",
    "        G.nodes[node]['gamma'] =  gamma[node].values[0]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "no_gamma_nodes = [node for node, data in G.nodes(data=True) if not data]\n",
    "\n",
    "for node in no_gamma_nodes: G.nodes[node]['gamma'] = np.nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f8e9bb6",
   "metadata": {},
   "source": [
    "### We have the `Networkx` Graph G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b1120803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 6157)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b8ad26",
   "metadata": {},
   "source": [
    "### Add more node features using data from GEM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23323d41",
   "metadata": {},
   "source": [
    "### Create a _node features_ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "30792ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compartements</th>\n",
       "      <th>metabolites</th>\n",
       "      <th>num_of_mets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_LACDcm</th>\n",
       "      <td>c|m</td>\n",
       "      <td>ficytc_m|focytc_m|lac__D_c|pyr_c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_LACDm</th>\n",
       "      <td>m</td>\n",
       "      <td>ficytc_m|focytc_m|lac__D_m|pyr_m</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_LACD2cm</th>\n",
       "      <td>c|m</td>\n",
       "      <td>ficytc_m|focytc_m|lac__L_c|pyr_c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          compartements                       metabolites num_of_mets\n",
       "D_LACDcm            c|m  ficytc_m|focytc_m|lac__D_c|pyr_c           4\n",
       "D_LACDm               m  ficytc_m|focytc_m|lac__D_m|pyr_m           4\n",
       "L_LACD2cm           c|m  ficytc_m|focytc_m|lac__L_c|pyr_c           4"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(index=list(G.nodes()), columns=['compartements', 'metabolites', 'num_of_mets'])\n",
    "\n",
    "for rxn in df.index:\n",
    "    if 'rev?' in rxn: rxn = rxn.split(\"?\")[1]\n",
    "    else: rxn = rxn\n",
    "\n",
    "    metabolites = []\n",
    "    for m in model.reactions.get_by_id(rxn).metabolites: metabolites.append(m.id)\n",
    "  \n",
    "    metabolites = \"|\".join(metabolites)\n",
    "    compartements = \"|\".join(list(model.reactions.get_by_id(rxn).compartments))\n",
    "\n",
    "    # compartements = list(model.reactions.get_by_id(rxn).compartments)\n",
    "    \n",
    "    num_of_mets = len(model.reactions.get_by_id(rxn).metabolites)\n",
    "    new_row = [compartements, metabolites, num_of_mets]\n",
    "\n",
    "    df.loc[rxn] = new_row\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "76fa6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODING to every compartement and metabolite\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def enc_for_every():\n",
    "    COBRA_METABOLITES = pd.DataFrame([m.id for m in model.metabolites])\n",
    "    COBRA_METABOLITES.rename(columns = {0:'id'}, inplace = True)\n",
    "    COBRA_METABOLITES['enc'] = LabelEncoder().fit_transform(COBRA_METABOLITES['id'])\n",
    "\n",
    "    COBRA_COMPARTEMETNS = pd.DataFrame(list(model.compartments.keys()))\n",
    "    COBRA_COMPARTEMETNS.rename(columns= {0:'id'}, inplace=True)\n",
    "    COBRA_COMPARTEMETNS['enc'] = LabelEncoder().fit_transform(COBRA_COMPARTEMETNS['id'])\n",
    "\n",
    "    for row in range(len(df)):\n",
    "\n",
    "        c = df.iloc[row]['compartements']\n",
    "        m = df.iloc[row]['metabolites']\n",
    "\n",
    "        try:\n",
    "            df.loc[df.index[row], 'compartements'] = ([dict(COBRA_COMPARTEMETNS.values).get(item, item) for item in c])\n",
    "            df.loc[df.index[row], 'metabolites'] = ([dict(COBRA_METABOLITES.values).get(item, item) for item in m])\n",
    "        except TypeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c4354d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding for c|m -> 0, ... \n",
    "df['compartements'] = LabelEncoder().fit_transform(df['compartements'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "101f3d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in list(G.nodes()):\n",
    "    if 'rev?' in node: rxn = node.split(\"?\")[1]\n",
    "    else: rxn = node\n",
    "\n",
    "    nx.set_node_attributes(G, {node: {'compartements':df.loc[rxn]['compartements']}})\n",
    "    # nx.set_node_attributes(G, {node: {'metabolites':df.loc[rxn]['metabolites']}})\n",
    "    nx.set_node_attributes(G, {node: {'num_of_mets':df.loc[rxn]['num_of_mets']}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c3c60206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/comex/Desktop/python-envs/main-bio/lib/python3.9/site-packages/networkx/algorithms/link_analysis/hits_alg.py:78: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G, nodelist=list(G), dtype=float)\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def orderDict(x: dict, desc=True):\n",
    "    return sorted(x.items(), key=itemgetter(1), reverse=desc)\n",
    "\n",
    "indg = orderDict(nx.in_degree_centrality(G))\n",
    "\n",
    "ccen = orderDict(nx.closeness_centrality(G))\n",
    "\n",
    "betcen = orderDict(nx.betweenness_centrality(G))\n",
    "\n",
    "pgrk = orderDict(nx.pagerank(G))\n",
    "\n",
    "hubs, autr = nx.hits(G)\n",
    "\n",
    "hubs = orderDict(hubs)\n",
    "autr = orderDict(autr)\n",
    "\n",
    "col_names = ['in-degree', 'closeness', 'betweness', 'page rank', 'autr', 'hubs']\n",
    "\n",
    "graphStats = pd.DataFrame(columns=col_names)\n",
    "\n",
    "graphStats['in-degree'] = [n for n, v in indg]\n",
    "graphStats['closeness'] = [n for n, v in ccen]\n",
    "graphStats['betweness'] = [n for n, v in betcen]\n",
    "graphStats['page rank'] = [n for n, v in pgrk]\n",
    "graphStats['autr'] = [n for n, v in autr]\n",
    "graphStats['hubs'] = [n for n, v in hubs]\n",
    "\n",
    "# print('Top:\\n')\n",
    "# display(df.head(10))\n",
    "# print('Bottom:\\n')\n",
    "# display(df.tail(10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20e3bea1",
   "metadata": {},
   "source": [
    "## Node2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce034259",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_labels = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "from karateclub import Node2Vec\n",
    "\n",
    "\" Perform node embedding using Node2Vec \"\n",
    "N2vec_model = Node2Vec(walk_number=10, walk_length=80,p=0.9 ,q=0.1,dimensions=12)\n",
    "N2vec_model.fit(G_labels)\n",
    "N2Vec_embedding = N2vec_model.get_embedding()\n",
    "print('Embedding array shape (nodes x features):',N2Vec_embedding.shape )\n",
    "\n",
    "df_embedding = pd.DataFrame(index=list(G.nodes), data=N2Vec_embedding)\n",
    "df_embedding.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec6c0e85",
   "metadata": {},
   "source": [
    "#### Clustering based on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e4c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(df_embedding)\n",
    "\n",
    "results = pd.DataFrame(columns=['cluster'], index=df_embedding.index)\n",
    "results['cluster'] = kmeans.labels_\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffaea5cd",
   "metadata": {},
   "source": [
    "## Networkx to Torch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5395fc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 6157], x=[373, 3], edge_attr=[6157, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(373, 6157)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data = from_networkx(G, group_node_attrs=all, group_edge_attrs=all)\n",
    "print(data)\n",
    "data.num_nodes ,data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b0b3a-7e2d-48ff-8407-3b84bbb81a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6c04a7e252f45ffc2f7191e380805b6a5dd99aa68793d835f69a35c16ce4a30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
